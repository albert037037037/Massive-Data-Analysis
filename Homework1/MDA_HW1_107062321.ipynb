{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done join\n",
      "Done map1\n",
      "Done reduce\n",
      "Done sort\n",
      "Done collect\n",
      "start output\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "def mapper1(line):\n",
    "    matrix = ''\n",
    "    i, j = '', ''\n",
    "    value = ''\n",
    "    tmp = 0\n",
    "    idone = False\n",
    "    jdone = False\n",
    "    \n",
    "    for ch in line:\n",
    "        if ch == 'M':\n",
    "            matrix = 'M'\n",
    "        elif ch == 'N':\n",
    "            matrix = 'N'\n",
    "        elif ch.isdigit():\n",
    "            if i == '' or idone == False:\n",
    "                i += ch\n",
    "            elif j == '' or jdone == False:\n",
    "                j += ch\n",
    "            else:\n",
    "                value += ch\n",
    "        else:\n",
    "            if tmp == 1:\n",
    "                idone = True\n",
    "            elif tmp == 2:\n",
    "                jdone = True\n",
    "            tmp+=1\n",
    "                \n",
    "    if matrix == 'M':\n",
    "        return (j, (matrix, i, value))\n",
    "    else:\n",
    "        return (i, (matrix, j, value))\n",
    "    \n",
    "def mapper2(tp):\n",
    "    i = int(tp[1][0][1])\n",
    "    k = int(tp[1][1][1])\n",
    "    Mnum = int(tp[1][0][2]) \n",
    "    Nnum = int(tp[1][1][2])\n",
    "    value = Mnum * Nnum\n",
    "    return ((i, k), value)\n",
    "\n",
    "file = sc.textFile(\"500input.txt\")\n",
    "matrixM = file.filter(lambda x: \"M\" in x)\n",
    "matrixN = file.filter(lambda x: \"N\" in x)\n",
    "\n",
    "newM = matrixM.map(mapper1)\n",
    "newN = matrixN.map(mapper1)\n",
    "\n",
    "newmatrix = newM.join(newN)\n",
    "#print(\"Done join\")\n",
    "newmatrix = newmatrix.map(mapper2)\n",
    "#print(\"Done map1\")\n",
    "newmatrix = newmatrix.reduceByKey(lambda a, b: a+b)\n",
    "#print(\"Done reduce\")\n",
    "newmatrix = newmatrix.sortByKey(ascending = True)\n",
    "#print(\"Done sort\")\n",
    "newmatrix = newmatrix.collect()\n",
    "#print(\"Done collect\")\n",
    "\n",
    "\n",
    "#print(\"start output\")\n",
    "outF = open(\"Outputfile.txt\", \"w\")\n",
    "for line in newmatrix:\n",
    "    outF.write((str(line[0][0]) + ',' + str(line[0][1]) + ',' + str(line[1])))\n",
    "    outF.write(\"\\n\")\n",
    "outF.close()\n",
    "    \n",
    "\n",
    "# for item in newmatrix:\n",
    "#     print(item[0][0] + ',' + item[0][1] + ',' + str(item[1]))\n",
    "    \n",
    "sc.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 107062321_HW1_report\n",
    "這次的作業要實作兩個大矩陣的乘法，透過MapReduce的理論概念來完成\n",
    "\n",
    "### 資料前處理\n",
    "\n",
    "一開始丟進來的資料會有$MN$矩陣混雜在一起\n",
    "\n",
    "我透過RDD filter的操作，將$MN$矩陣的資料分開\n",
    "\n",
    "\n",
    "### mapper1\n",
    "\n",
    "+ $MN$乘出來的矩陣$P$，其中每一個$P_{ik}$項的運算過程為$P_{ij} = \\sum M_{ik}N_{kj}$\n",
    "\n",
    "從這個概念，我做了第一個Map function\n",
    "\n",
    "由於不能使用pylist，所以我就把每一行txt檔的文字用for迴圈掃過一次，寫一些判斷式，即可把需要的資訊抓下來。\n",
    "\n",
    "把需要的資訊拿到後，要回傳的 key vlaue pair的形式為 :\n",
    "\n",
    "+ 若為$M$矩陣，回傳 ( j, (matrix, i, value) )，j 代表$M$矩陣的哪個column，matrix代表是$M$或$N$，i 代表$M$矩陣的哪個row，value則代表$M_{ij}$的值\n",
    "\n",
    "+ 若為$N$矩陣，回傳 ( i, (matrix, j, value) )，j 代表$N$矩陣的哪個row，matrix代表是$M$或$N$，i 代表$N$矩陣的哪個column，value則代表$N_{ji}$的值 (也就是$N_{jk}$，但因為是方陣，為了code的簡化故這樣寫）\n",
    "\n",
    "### join\n",
    "\n",
    "把前面分開的$MN$矩陣分別丟進mapper1，map好之後，會得到$MN$分開的RDD，將這兩個RDD透過join的操作，即可所有擁有相同key值( j )，並且分別屬於$MN$兩個矩陣，會長得像 ( j , ((M, i, v1), (N, k, v2)))\n",
    "\n",
    "### mapper2\n",
    "\n",
    "在mapper2中，我根據上面join過後的資料結構，取出$M$矩陣的 i 值，$N$矩陣的 j 值，再將 v1 乘以 v2 得到這兩個位置相乘的value後，包成$( ( i, k ), P_{ikvalue})$ 的結構，回傳回去。\n",
    "\n",
    "### reducer\n",
    "\n",
    "在這裡，由於我們要將有相同key $(i,k)$的 value 全部相加起來，這樣才是$P_{ik}$的真正總和\n",
    "\n",
    "故使用了reduceByKey，讓有相同Key值的value去執行我的reduce function\n",
    "\n",
    "而我的reducer要做的事情，也就只是，傳進a, b兩個value後，兩個相加，回傳回去。\n",
    "\n",
    "### Output\n",
    "\n",
    "我原本的做法是直接collect起來後輸出，但經過測試後發現，若沒有自己去排序的話，會無法達到項要求要做的排序好的狀態\n",
    "\n",
    "於是我使用RDD的 `sortByKey(ascending = True)` 的操作\n",
    "\n",
    "再collect起來的話，就可以是排序後的樣子了。\n",
    "\n",
    "最後，將上述的output用python的open 和 write即可寫進外部txt檔\n",
    "\n",
    "\n",
    "### 參考網站\n",
    "https://blog.csdn.net/helloxiaozhe/article/details/78481784\n",
    "\n",
    "https://www.cnblogs.com/fang-jie/articles/6138789.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
